import time
from typing import List, Tuple
from ..config import GEMINI_MODEL_NAME
from ..state import append_log, update_state
from ..utils import get_timestamp, safe_bucket_path
from .filesystem import save_generation_outputs

def load_vertex_components():
    try:
        import google.auth
        import vertexai
        from vertexai.preview.generative_models import (
            GenerativeModel,
            GenerationConfig,
            Image as VertexImage,
            Part,
        )
    except Exception as exc:
        raise RuntimeError(
            "æ— æ³•åŠ è½½ Vertex AI SDKï¼Œè¯·ç¡®è®¤å·²å®‰è£… google-auth ä¸ vertexai ç›¸å…³ä¾èµ–"
        ) from exc

    return google.auth, vertexai, GenerativeModel, GenerationConfig, VertexImage, Part

def generate_images_worker(
    prompt: str,
    filenames: List[str],
    bucket: str,
    overwrite: bool,
    key_path: str,
    project_id: str,
    location: str,
) -> None:
    total = len(filenames)
    update_state(
        "image_generation",
        status="running",
        progress=0,
        processed=0,
        total=total,
        message="æ­£åœ¨åˆå§‹åŒ– Vertex AI",
        prompt=prompt,
        bucket=bucket,
    )
    append_log("image_generation", f"[{get_timestamp()}] ğŸ§  å¼€å§‹æ‰¹é‡ç”Ÿæˆä»»åŠ¡ï¼Œå…± {total} å¼ å›¾ç‰‡")

    try:
        (
            google_auth,
            vertexai,
            GenerativeModel,
            GenerationConfig,
            VertexImage,
            Part,
        ) = load_vertex_components()
        credentials, _ = google_auth.load_credentials_from_file(key_path)
        vertexai.init(project=project_id, location=location, credentials=credentials)
        model = GenerativeModel(GEMINI_MODEL_NAME)
        generation_config = GenerationConfig(temperature=0.4, top_p=0.95, top_k=32)
    except Exception as exc:
        append_log("image_generation", f"[{get_timestamp()}] âŒ åˆå§‹åŒ–å¤±è´¥ï¼š{exc}")
        update_state("image_generation", status="error", message=str(exc))
        return

    # Queue format: [(relative_path, attempt_count)]
    queue: List[Tuple[str, int]] = [(f, 0) for f in filenames]
    processed_count = 0
    
    MAX_RETRIES = 3
    RPM_DELAY = 7  # 10 RPM = 6s/req. Use 7s to be safe.

    while queue:
        relative_path, attempts = queue.pop(0)
        
        try:
            source_path = safe_bucket_path(bucket, relative_path)
        except ValueError as exc:
            append_log("image_generation", f"[{get_timestamp()}] âš ï¸ è·³è¿‡éæ³•è·¯å¾„ï¼š{relative_path} ({exc})")
            processed_count += 1
            continue

        if not source_path.exists():
            append_log("image_generation", f"[{get_timestamp()}] âš ï¸ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{relative_path}")
            processed_count += 1
            continue

        append_log("image_generation", f"[{get_timestamp()}] ğŸ¯ æ­£åœ¨ç”Ÿæˆï¼š{relative_path} (ç¬¬ {attempts + 1} æ¬¡å°è¯•)")
        
        success = False
        try:
            request_parts = [
                Part.from_text(prompt),
                Part.from_image(VertexImage.load_from_file(str(source_path))),
            ]
            response = model.generate_content(request_parts, generation_config=generation_config)
            payloads = []
            for candidate in getattr(response, "candidates", []) or []:
                content = getattr(candidate, "content", None)
                if not content:
                    continue
                for part in getattr(content, "parts", []):
                    inline_data = getattr(part, "inline_data", None)
                    if inline_data and getattr(inline_data, "data", None):
                        payloads.append(inline_data.data)
            if not payloads and hasattr(response, "images"):
                for image in getattr(response, "images", []):
                    raw = getattr(image, "_image_bytes", None)
                    if raw:
                        payloads.append(raw)

            if not payloads:
                raise RuntimeError("æœªä» Gemini å“åº”ä¸­è·å–åˆ°ä»»ä½•å›¾åƒæ•°æ®")

            saved = save_generation_outputs(payloads, relative_path, bucket, overwrite)
            append_log(
                "image_generation",
                f"[{get_timestamp()}] âœ… å®Œæˆ {relative_path}ï¼Œè¾“å‡º {len(saved)} ä¸ªæ–‡ä»¶",
            )
            success = True
            processed_count += 1
            
        except Exception as exc:
            append_log(
                "image_generation",
                f"[{get_timestamp()}] âŒ ç”Ÿæˆ {relative_path} å¤±è´¥ï¼š{exc}",
            )
            attempts += 1
            if attempts < MAX_RETRIES:
                append_log("image_generation", f"[{get_timestamp()}] ğŸ”„ å·²é‡æ–°åŠ å…¥é˜Ÿåˆ—ï¼Œç¨åé‡è¯•...")
                queue.append((relative_path, attempts))
            else:
                append_log("image_generation", f"[{get_timestamp()}] ğŸš« è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤å›¾ç‰‡")
                processed_count += 1

        # RPM Rate Limiting
        # Wait regardless of success or failure to respect API limits
        # Unless queue is empty (done)
        if queue:
             append_log("image_generation", f"[{get_timestamp()}] â³ ç­‰å¾… {RPM_DELAY} ç§’ä»¥æ»¡è¶³ API é™åˆ¶...")
             time.sleep(RPM_DELAY)

        progress = int(processed_count / total * 100)
        update_state(
            "image_generation",
            progress=progress,
            processed=processed_count,
            message=f"å·²å¤„ç† {processed_count}/{total} å¼ å›¾ç‰‡ (é˜Ÿåˆ—å‰©ä½™ {len(queue)})",
        )

    update_state("image_generation", status="success", message="å…¨éƒ¨å›¾ç‰‡ç”Ÿæˆå®Œæˆ", progress=100)

